{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attempted-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "from collections import deque\n",
    "import random\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stylish-gender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>43.075001</td>\n",
       "      <td>42.314999</td>\n",
       "      <td>43.064999</td>\n",
       "      <td>41.310070</td>\n",
       "      <td>102223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>43.132500</td>\n",
       "      <td>43.637501</td>\n",
       "      <td>42.990002</td>\n",
       "      <td>43.057499</td>\n",
       "      <td>41.302879</td>\n",
       "      <td>118071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>43.134998</td>\n",
       "      <td>43.367500</td>\n",
       "      <td>43.020000</td>\n",
       "      <td>43.257500</td>\n",
       "      <td>41.494736</td>\n",
       "      <td>89738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>43.360001</td>\n",
       "      <td>43.842499</td>\n",
       "      <td>43.262501</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>41.967163</td>\n",
       "      <td>94640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>43.587502</td>\n",
       "      <td>43.902500</td>\n",
       "      <td>43.482498</td>\n",
       "      <td>43.587502</td>\n",
       "      <td>41.811283</td>\n",
       "      <td>82271200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close  Adj Close     Volume\n",
       "0 2018-01-02  42.540001  43.075001  42.314999  43.064999  41.310070  102223600\n",
       "1 2018-01-03  43.132500  43.637501  42.990002  43.057499  41.302879  118071600\n",
       "2 2018-01-04  43.134998  43.367500  43.020000  43.257500  41.494736   89738400\n",
       "3 2018-01-05  43.360001  43.842499  43.262501  43.750000  41.967163   94640000\n",
       "4 2018-01-08  43.587502  43.902500  43.482498  43.587502  41.811283   82271200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.pdr_override()\n",
    "df_full = pdr.get_data_yahoo(\"AAPL\", start=\"2018-01-01\").reset_index()\n",
    "df_full.to_csv('aapl.csv',index=False)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-gibson",
   "metadata": {},
   "source": [
    "Define the Q-Learning Agent\n",
    "The first function is the Agent class defines the state size, window size, batch size, deque which is the memory used, inventory as a list. It also defines some static variables like epsilon, decay, gamma, etc. Two neural network layers are defined for the buy, hold, and sell call. The GradientDescentOptimizer is also used.\n",
    "\n",
    "The Agent has functions defined for buy and sell options. The get_state and act function makes use of the Neural network for generating the next state of the neural network. The rewards are subsequently calculated by adding or subtracting the value generated by executing the call option. The action taken at the next state is influenced by the action taken on the previous state. 1 refers to a Buy call while 2 refers to a Sell call. In every iteration, the state is determined on the basis of which an action is taken which will either buy or sell some stocks. The overall rewards are stored in the total profit variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mounted-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df_full.copy()\n",
    "name = 'Q-learning agent'\n",
    "class Agent:\n",
    "    def __init__(self, state_size, window_size, trend, skip, batch_size):\n",
    "        self.state_size = state_size\n",
    "        self.window_size = window_size\n",
    "        self.half_window = window_size // 2\n",
    "        self.trend = trend\n",
    "        self.skip = skip\n",
    "        self.action_size = 3\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen = 1000)\n",
    "        self.inventory = []\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 0.5\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.999\n",
    "        tf.reset_default_graph()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.X = tf.placeholder(tf.float32, [None, self.state_size])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, self.action_size])\n",
    "        feed = tf.layers.dense(self.X, 256, activation = tf.nn.relu)\n",
    "        self.logits = tf.layers.dense(feed, self.action_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(1e-5).minimize(self.cost)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def act(self, state):\n",
    "        if random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        return np.argmax(self.sess.run(self.logits, feed_dict = {self.X: state})[0])\n",
    "    \n",
    "    def get_state(self, t):\n",
    "        window_size = self.window_size + 1\n",
    "        d = t - window_size + 1\n",
    "        block = self.trend[d : t + 1] if d >= 0 else -d * [self.trend[0]] + self.trend[0 : t + 1]\n",
    "        res = []\n",
    "        for i in range(window_size - 1):\n",
    "            res.append(block[i + 1] - block[i])\n",
    "        return np.array([res])\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        mini_batch = []\n",
    "        l = len(self.memory)\n",
    "        for i in range(l - batch_size, l):\n",
    "            mini_batch.append(self.memory[i])\n",
    "        replay_size = len(mini_batch)\n",
    "        X = np.empty((replay_size, self.state_size))\n",
    "        Y = np.empty((replay_size, self.action_size))\n",
    "        states = np.array([a[0][0] for a in mini_batch])\n",
    "        new_states = np.array([a[3][0] for a in mini_batch])\n",
    "        Q = self.sess.run(self.logits, feed_dict = {self.X: states})\n",
    "        Q_new = self.sess.run(self.logits, feed_dict = {self.X: new_states})\n",
    "        for i in range(len(mini_batch)):\n",
    "            state, action, reward, next_state, done = mini_batch[i]\n",
    "            target = Q[i]\n",
    "            target[action] = reward\n",
    "            if not done:\n",
    "                target[action] += self.gamma * np.amax(Q_new[i])\n",
    "            X[i] = state\n",
    "            Y[i] = target\n",
    "        cost, _ = self.sess.run(\n",
    "            [self.cost, self.optimizer], feed_dict = {self.X: X, self.Y: Y}\n",
    "        )\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        return cost\n",
    "    \n",
    "    def buy(self, initial_money):\n",
    "        starting_money = initial_money\n",
    "        states_sell = []\n",
    "        states_buy = []\n",
    "        inventory = []\n",
    "        state = self.get_state(0)\n",
    "        for t in range(0, len(self.trend) - 1, self.skip):\n",
    "            action = self.act(state)\n",
    "            next_state = self.get_state(t + 1)\n",
    "            if action == 1 and initial_money >= self.trend[t] and t < (len(self.trend) - self.half_window):\n",
    "                inventory.append(self.trend[t])\n",
    "                initial_money -= self.trend[t]\n",
    "                states_buy.append(t)\n",
    "                print('day %d: buy 1 unit at price %f, total balance %f'% (t, self.trend[t], initial_money))\n",
    "            elif action == 2 and len(inventory):\n",
    "                bought_price = inventory.pop(0)\n",
    "                initial_money += self.trend[t]\n",
    "                states_sell.append(t)\n",
    "                try:\n",
    "                    invest = ((close[t] - bought_price) / bought_price) * 100\n",
    "                except:\n",
    "                    invest = 0\n",
    "                print(\n",
    "                    'day %d, sell 1 unit at price %f, investment %f %%, total balance %f,'\n",
    "                    % (t, close[t], invest, initial_money)\n",
    "                )\n",
    "            state = next_state\n",
    "        invest = ((initial_money - starting_money) / starting_money) * 100\n",
    "        total_gains = initial_money - starting_money\n",
    "        return states_buy, states_sell, total_gains, invest\n",
    "    \n",
    "    def train(self, iterations, checkpoint, initial_money):\n",
    "        for i in range(iterations):\n",
    "            total_profit = 0\n",
    "            inventory = []\n",
    "            state = self.get_state(0)\n",
    "            starting_money = initial_money\n",
    "            for t in range(0, len(self.trend) - 1, self.skip):\n",
    "                action = self.act(state)\n",
    "                next_state = self.get_state(t + 1)\n",
    "                if action == 1 and starting_money >= self.trend[t] and t < (len(self.trend) - self.half_window):\n",
    "                    inventory.append(self.trend[t])\n",
    "                    starting_money -= self.trend[t]\n",
    "                elif action == 2 and len(inventory) > 0:\n",
    "                    bought_price = inventory.pop(0)\n",
    "                    total_profit += self.trend[t] - bought_price\n",
    "                    starting_money += self.trend[t]\n",
    "                invest = ((starting_money - initial_money) / initial_money)\n",
    "                self.memory.append((state, action, invest, next_state, starting_money < initial_money))\n",
    "                state = next_state\n",
    "                batch_size = min(self.batch_size, len(self.memory))\n",
    "                cost = self.replay(batch_size)\n",
    "            if (i+1) % checkpoint == 0:\n",
    "                print('epoch: %d, total rewards: %f.3, cost: %f, total money: %f'%(i + 1, total_profit, cost,starting_money))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mukane\\anaconda3\\envs\\my_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, total rewards: 155.847557.3, cost: 0.225760, total money: 10155.847557\n",
      "epoch: 20, total rewards: 155.352539.3, cost: 0.152596, total money: 10155.352539\n",
      "epoch: 30, total rewards: 142.110069.3, cost: 0.111049, total money: 10142.110069\n"
     ]
    }
   ],
   "source": [
    "close = df.Close.values.tolist()\n",
    "initial_money = 10000\n",
    "window_size = 30\n",
    "skip = 1\n",
    "batch_size = 32\n",
    "agent = Agent(state_size = window_size, window_size = window_size, trend = close, skip = skip, batch_size = batch_size)\n",
    "agent.train(iterations = 200, checkpoint = 10, initial_money = initial_money)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,5))\n",
    "plt.plot(close, color='r', lw=2.)\n",
    "plt.plot(close, '^', markersize=10, color='m', label = 'buying signal', markevery = states_buy)\n",
    "plt.plot(close, 'v', markersize=10, color='k', label = 'selling signal', markevery = states_sell)\n",
    "plt.title('total gains %f, total investment %f%%'%(total_gains, invest))\n",
    "plt.legend()\n",
    "plt.savefig(name+'.png')\n",
    "plt.show("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
